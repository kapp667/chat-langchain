# Test Manuel - Claude Desktop MCP avec Sonnet 4.5

**Date:** 3 octobre 2025
**Objectif:** Valider que Claude Desktop MCP utilise bien Sonnet 4.5 et constater l'am√©lioration

## Pr√©-requis

‚úÖ Backend LangGraph en cours d'ex√©cution (`http://localhost:2024`)
‚úÖ Claude Desktop install√© et configur√©
‚úÖ MCP server `langchain-expert` actif

## Test 1 : Question Simple (Baseline)

### Question √† Poser
```
@langchain-expert I need to save conversation history to PostgreSQL.
Which class should I use?
```

### R√©sultat Attendu avec Sonnet 4.5

**‚è±Ô∏è Vitesse:** ~22-30 secondes
**üìè Longueur:** ~1,400-1,500 caract√®res
**‚úÖ Qualit√©:** R√©ponse compl√®te avec :
- Nom de la classe pr√©cis (`PostgresChatMessageHistory`)
- Exemple de code Python et JavaScript
- Variantes (Google Cloud SQL)
- Mention du `session_id`

### Comparaison GPT-5 Mini (Ancien)
- **Vitesse:** ~60 secondes (2√ó plus lent)
- **Longueur:** ~1,000-1,200 caract√®res
- **Qualit√©:** Bonne mais moins de d√©tails

## Test 2 : Question Complexe (Challenge)

### Question √† Poser
```
@langchain-expert I want to build a research assistant that:
(1) breaks down complex questions into sub-questions,
(2) searches documentation for each sub-question,
(3) synthesizes findings.
How should I structure this?
```

### R√©sultat Attendu avec Sonnet 4.5

**‚è±Ô∏è Vitesse:** ~35-45 secondes
**üìè Longueur:** ~3,900-4,200 caract√®res
**‚úÖ Qualit√©:** R√©ponse ultra-d√©taill√©e avec :
- Architecture overview avec LangGraph
- Code examples pour chaque composant
- Query decomposition node
- Retrieval node
- Synthesis node
- Agent vs Chain comparaison
- Liens vers documentation

### Comparaison GPT-5 Mini (Ancien)
- **Vitesse:** ~120 secondes (2.7√ó plus lent)
- **Longueur:** ~2,500 caract√®res
- **Qualit√©:** Bonne mais moins exhaustive

## Test 3 : Question Ultra-Complexe (Stress Test)

### Question √† Poser
```
@langchain-expert I want to create a planning agent that explores
multiple solution paths, can backtrack when hitting dead ends, and
maintains a tree of attempted strategies. How do I implement this
with LangGraph?
```

### R√©sultat Attendu avec Sonnet 4.5

**‚è±Ô∏è Vitesse:** ~45-50 secondes
**üìè Longueur:** ~5,700+ caract√®res
**‚úÖ Qualit√©:** R√©ponse exhaustive avec :
- Tree-of-Thoughts pattern explanation
- State management code
- Backtracking logic
- Send API pour parall√©lisation
- BFS vs DFS strategies
- Complete example code
- **Pas de troncature** (crucial!)

### Comparaison GPT-5 Mini (Ancien)
- **Vitesse:** ~160+ secondes (3.3√ó plus lent)
- **Longueur:** ~3,000 caract√®res
- **Qualit√©:** Bonne mais **risque de troncature**

## Grille d'√âvaluation

| Crit√®re | Attendu Sonnet 4.5 | Observ√© | ‚úÖ/‚ùå |
|---------|-------------------|---------|------|
| **Test 1 - Vitesse** | 22-30s | ___ s | ___ |
| **Test 1 - Longueur** | 1,400-1,500 chars | ___ chars | ___ |
| **Test 1 - Compl√©tude** | Classes + exemples + variantes | ___ | ___ |
| **Test 2 - Vitesse** | 35-45s | ___ s | ___ |
| **Test 2 - Longueur** | 3,900-4,200 chars | ___ chars | ___ |
| **Test 2 - Architecture** | Overview + 3 nodes + code | ___ | ___ |
| **Test 3 - Vitesse** | 45-50s | ___ s | ___ |
| **Test 3 - Longueur** | 5,700+ chars | ___ chars | ___ |
| **Test 3 - Pas de troncature** | R√©ponse compl√®te jusqu'au bout | ___ | ___ |

## R√©sultats de Benchmark (R√©f√©rence)

D'apr√®s `hero_vs_pragmatic_sonnet45_results.json` :

| Question | Complexit√© | Temps | Chars | Statut |
|----------|-----------|-------|-------|--------|
| Q1 (PostgreSQL class) | Trivial | 22.4s | 1,440 | ‚úÖ |
| Q2 (Configuration) | Simple | 28.7s | 1,695 | ‚úÖ |
| Q3 (Integration) | Mod√©r√© | 35.1s | 3,054 | ‚úÖ |
| Q4 (Debugging) | Mod√©r√©-complexe | 39.1s | 4,016 | ‚úÖ |
| Q5 (Architecture) | Complexe | 41.0s | 3,928 | ‚úÖ |
| **Q6 (Planning agent)** | **Ultra-complexe** | **47.1s** | **5,734** | ‚úÖ |

## Exp√©rience Utilisateur Attendue

### Avant (GPT-5 Mini)
```
Question pos√©e ‚Üí ‚è≥ Attente 60-120s ‚Üí R√©ponse bonne mais basique
‚Üí Parfois besoin de re-questionner pour d√©tails
‚Üí Frustration sur questions complexes (lenteur)
```

### Apr√®s (Sonnet 4.5)
```
Question pos√©e ‚Üí ‚è≥ Attente 30-45s ‚Üí R√©ponse exhaustive imm√©diatement
‚Üí Rarement besoin de follow-up
‚Üí Satisfaction : vitesse + qualit√©
```

**Gain de productivit√© estim√©:** 2-3√ó (vitesse + moins de re-questions)

## Troubleshooting

### R√©ponse trop lente (>60s)
1. V√©rifier backend : `curl http://localhost:2024/ok`
2. V√©rifier logs : `docker logs langgraph-backend`
3. V√©rifier mod√®le configur√© :
   ```bash
   grep "query_model" backend/retrieval_graph/configuration.py
   # Doit afficher: default="anthropic/claude-sonnet-4-5-20250929"
   ```

### R√©ponse courte (<1000 chars sur questions complexes)
1. Possible probl√®me de troncature
2. V√©rifier version du mod√®le (doit √™tre `20250929`)
3. Signaler dans monitoring (semaine 1)

### R√©ponse semble identique √† avant
1. V√©rifier que le backend a bien red√©marr√© apr√®s changement config
2. Relancer : `docker compose restart langgraph`
3. Retester apr√®s 30 secondes

## Validation Finale

**Pour confirmer que Sonnet 4.5 est actif :**

‚úÖ **Vitesse** : Questions complexes < 45s (vs ~120s avant)
‚úÖ **Qualit√©** : R√©ponses ultra-d√©taill√©es (3,000-5,700 chars)
‚úÖ **Compl√©tude** : Pas de troncature sur questions ultra-complexes
‚úÖ **Exp√©rience** : R√©ponses "wow" d√®s la premi√®re fois

**Si tous ces crit√®res sont remplis ‚Üí Sonnet 4.5 confirm√© ! üéâ**

---

**Date de test:** _______________
**Testeur:** _______________
**Verdict:** ‚úÖ Sonnet 4.5 actif / ‚ùå Probl√®me d√©tect√©

**Notes:**
```


```

**Co-authored-by: St√©phane Wootha Richard <stephane@sawup.fr>**
