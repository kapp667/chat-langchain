# Quick Start - MCP Server pour Claude Desktop

Ce guide vous permet de d√©marrer le serveur MCP LangChain Expert en 15 minutes.

---

## Pr√©requis (5 min)

### Logiciels Requis
- **Docker Desktop** - [T√©l√©charger](https://www.docker.com/products/docker-desktop)
- **Python 3.11+** - V√©rifier: `python3 --version`
- **Poetry** - Installer: `curl -sSL https://install.python-poetry.org | python3 -`
- **Claude Desktop** - [T√©l√©charger](https://claude.ai/download)

### Cl√©s API Requises
- **OpenAI API Key** - Pour embeddings et LLM ([obtenir ici](https://platform.openai.com/api-keys))
- **LangSmith API Key** (optionnel) - Pour tracing ([obtenir ici](https://smith.langchain.com))

---

## Installation Rapide (10 min)

### 1. Infrastructure Docker (2 min)

D√©marrer PostgreSQL, Weaviate et Redis :

```bash
docker compose up -d
```

V√©rifier que les 3 conteneurs tournent :
```bash
docker ps
# Doit afficher: postgres, weaviate, redis
```

### 2. Configuration Environment (1 min)

Copier le template et √©diter avec vos cl√©s :

```bash
cp .env.example .env
# √âditer .env avec votre √©diteur
```

**Variables essentielles dans `.env` :**
```bash
# OpenAI (REQUIS)
OPENAI_API_KEY=sk-proj-...

# Weaviate (local Docker)
WEAVIATE_URL=http://localhost:8088

# PostgreSQL (local Docker)
POSTGRES_CONNECTION_STRING=postgresql://postgres:password@localhost:5432/chat_langchain

# LangSmith (OPTIONNEL - free tier 5k traces/mois)
LANGSMITH_API_KEY=lsv2_pt_...
LANGCHAIN_TRACING_V2=true
```

### 3. Installation Dependencies (2 min)

```bash
poetry install
```

### 4. Ingestion Documentation (30-60 min - √† faire 1x)

Cette √©tape indexe toute la documentation LangChain :

```bash
PYTHONPATH=. poetry run python backend/ingest.py
```

**Progression attendue :**
```
Indexing LangChain documentation...
‚úì Fetched 1,200+ pages
‚úì Split into 15,061 chunks
‚úì Created embeddings (OpenAI text-embedding-3-small)
‚úì Stored in Weaviate
‚úì Updated Record Manager (PostgreSQL)
Done! 15,061 documents indexed
```

> **Note:** Cette √©tape prend 30-60 min mais ne se fait qu'une fois. Les runs suivants seront incr√©mentaux (seulement nouveaux docs).

### 5. D√©marrer LangGraph Server (1 min)

Terminal d√©di√© pour le serveur :

```bash
langgraph dev --no-browser --port 2024
```

**Succ√®s si vous voyez :**
```
‚úì Compiled graph successfully
‚úì Server running on http://localhost:2024
‚úì Endpoints: /threads, /runs/stream, /state
```

> **Important:** Garder ce terminal ouvert pendant l'utilisation du MCP.

### 6. Configuration Claude Desktop (2 min)

√âditer le fichier de configuration :

**macOS:**
```bash
code ~/Library/Application\ Support/Claude/claude_desktop_config.json
```

**Ajouter cette configuration :**
```json
{
  "mcpServers": {
    "langchain-expert": {
      "command": "uv",
      "args": [
        "--directory",
        "/Users/VOTRE_USER/Documents/work/chat-langchain/mcp_server",
        "run",
        "langchain_expert.py"
      ]
    }
  }
}
```

> **Remplacer** `/Users/VOTRE_USER/` par votre chemin absolu r√©el.

### 7. Red√©marrer Claude Desktop (30 sec)

```bash
# macOS: Cmd+Q pour quitter
# Puis relancer Claude Desktop
```

---

## V√©rification Installation

### Test 1: V√©rifier Status MCP

Dans Claude Desktop, taper :
```
Check LangChain expert status
```

**R√©ponse attendue :**
```
‚úÖ LangGraph Server: Connected (http://localhost:2024)
‚úÖ Documents indexed: 15,061
‚úÖ Models available: GPT-5 mini (default), Claude Sonnet 4.5, DeepSeek, Llama 3.3 70B
‚úÖ Weaviate: Connected (15,061 vectors)
‚úÖ PostgreSQL: Connected (checkpoints + record manager)
```

### Test 2: Question Simple

```
I need to save conversation history to PostgreSQL. Which class should I use?
```

**R√©ponse attendue :**
```
Based on the documentation, you should use PostgresChatMessageHistory...
[r√©ponse avec citations et code examples]
```

### Test 3: Question Complexe

```
How do I build a research assistant that breaks down complex questions into sub-questions, searches for each, and synthesizes findings?
```

**R√©ponse attendue :**
```
Based on the documentation, here's how to structure your research assistant using LangGraph:
[architecture compl√®te avec code TypeScript/Python]
```

---

## Utilisation Quotidienne

### D√©marrage Rapide (apr√®s installation initiale)

```bash
# 1. D√©marrer infrastructure (si arr√™t√©e)
docker compose up -d

# 2. D√©marrer LangGraph server
langgraph dev --no-browser --port 2024

# 3. Lancer Claude Desktop
```

### Arr√™t Propre

```bash
# 1. Arr√™ter LangGraph (Ctrl+C dans terminal)

# 2. Arr√™ter infrastructure (optionnel)
docker compose down
```

---

## Commandes Utiles

### Mise √† Jour Documentation

Pour re-indexer (nouveaux docs LangChain) :

```bash
FORCE_UPDATE=true PYTHONPATH=. poetry run python backend/ingest.py
```

### V√©rifier Infrastructure

```bash
# V√©rifier Docker containers
docker ps

# V√©rifier PostgreSQL
docker exec -it postgres psql -U postgres -d chat_langchain -c "SELECT COUNT(*) FROM langchain_pg_collection;"

# V√©rifier Weaviate
curl http://localhost:8088/v1/meta
```

### Logs Debugging

```bash
# Logs LangGraph server (si probl√®mes)
# Visible dans le terminal o√π vous avez lanc√© 'langgraph dev'

# Logs Docker
docker logs postgres
docker logs weaviate
docker logs redis
```

---

## Mod√®les Disponibles

Le MCP server supporte plusieurs mod√®les LLM :

| Mod√®le | Usage | Vitesse | Qualit√© |
|--------|-------|---------|---------|
| **GPT-5 mini** | Default (upstream) | 60s | 4/5 |
| Claude Sonnet 4.5 | HERO (recommand√©) | 35s | 5/5 ‚≠ê |
| Llama 3.3 70B (Groq) | PRAGMATIC ultra-rapide | 9s | 4.6/5 |
| DeepSeek Chat | √âconomique | 45s | 4.4/5 |

> **Recommandation:** Configurer Sonnet 4.5 comme default pour qualit√© maximale (5/5). Qualit√© sup√©rieure justifie le d√©lai (voir [docs/research/benchmarks/ANALYSE_QUALITATIVE_HERO_VS_PRAGMATIC.md](./docs/research/benchmarks/ANALYSE_QUALITATIVE_HERO_VS_PRAGMATIC.md)). Configuration par d√©faut upstream utilise GPT-5 mini.

---

## Prochaines √âtapes

‚úÖ **Installation termin√©e !**

- üìö **Documentation compl√®te:** Voir [CLAUDE.md](./CLAUDE.md)
- üîß **Troubleshooting:** Voir [TROUBLESHOOTING.md](./TROUBLESHOOTING.md)
- üèóÔ∏è **Architecture:** Voir [docs/upstream/CONCEPTS.md](./docs/upstream/CONCEPTS.md)
- üéØ **Personnalisation:** Voir [docs/upstream/MODIFY.md](./docs/upstream/MODIFY.md)

### Questions Fr√©quentes

**Q: Le serveur MCP ne r√©pond pas ?**
‚Üí V√©rifier que `langgraph dev` tourne sur port 2024

**Q: "404 Not Found /invoke" ?**
‚Üí Vous utilisez le mauvais pattern API, voir [TROUBLESHOOTING.md](./TROUBLESHOOTING.md#probl√®me-404-not-found-invoke)

**Q: R√©ponses lentes (> 60s) ?**
‚Üí Normal pour questions complexes avec Sonnet 4.5. Utiliser Llama 3.3 70B si vitesse critique.

**Q: Hallucinations d√©tect√©es ?**
‚Üí Wrappers PNL anti-hallucination actifs par d√©faut (voir [docs/mcp_development/DOCUMENTATION_WRAPPERS_PNL.md](./docs/mcp_development/DOCUMENTATION_WRAPPERS_PNL.md))

---

## Support

- **Issues GitHub:** [chat-langchain/issues](https://github.com/langchain-ai/chat-langchain/issues)
- **Documentation officielle:** [python.langchain.com](https://python.langchain.com)
- **LangGraph docs:** [langchain-ai.github.io/langgraph](https://langchain-ai.github.io/langgraph)
